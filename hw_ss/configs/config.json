{
  "name": "default_config",
  "n_gpu": 1,
  "preprocessing": {
    "sr": 16000,
    "spectrogram": {
      "type": "MelSpectrogram",
      "args": {
      }
    },
    "log_spec": false
  },
  "augmentations": {
    "wave": [],
    "spectrogram": []
  },
  "arch": {
    "type": "SpexPlus",
    "args": {
      "num_spks": 25
    }
  },
  "data": {
    "train": {
      "batch_size": 4,
      "num_workers": 0,
      "datasets": [
        {
          "type": "LibrispeechDataset",
          "args": {
            "part": "train-clean-100",
            "limit": 4,
            "num_speakers": 25,
            "dataset_size": 1000,
            "audio_len": 3
          }
        }
      ]
    },
    "val": {
      "batch_size": 4,
      "num_workers": 0,
      "datasets": [
        {
          "type": "LibrispeechDataset",
          "args": {
            "part": "test-clean",
            "limit": 4,
            "num_speakers": 25,
            "dataset_size": 100,
            "audio_len": 3
          }
        }
      ]
    }
  },
  "optimizer": {
    "type": "Adam",
    "args": {
      "lr": 1e-3,
      "weight_decay": 1e-5
    }
  },
  "loss": {
    "type": "SpexLoss",
    "args": {}
  },
  "metrics": [],
  "lr_scheduler": {
    "type": "OneCycleLR",
    "args": {
      "steps_per_epoch": 100,
      "epochs": 100,
      "anneal_strategy": "cos",
      "max_lr": 1e-3,
      "pct_start": 0.2
    }
  },
  "trainer": {
    "epochs": 100,
    "save_dir": "saved/",
    "save_period": 5,
    "verbosity": 2,
    "monitor": "min val_loss",
    "early_stop": 600,
    "visualize": "wandb",
    "wandb_project": "speech_separation_project",
    "grad_norm_clip": 10,
    "len_epoch": 100
  }
}
